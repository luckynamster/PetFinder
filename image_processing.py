# image_processing.py
import numpy as np
from PIL import Image
import requests
from io import BytesIO
from sentence_transformers import SentenceTransformer
from pathlib import Path
import logging


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—É—é –º–æ–¥–µ–ª—å CLIP –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
# –≠—Ç–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —á–∏—Å–ª–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
try:
    model = SentenceTransformer('clip-ViT-B-32')
    logger.info("‚úÖ CLIP –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CLIP: {str(e)}")
    raise


# =============================================
# –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ó–ê–ì–†–£–ó–ö–ò –ò –û–ë–†–ê–ë–û–¢–ö–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô
# =============================================
def get_image_embedding(image_input) -> np.ndarray:

    try:
        # --------------------------------------------------
        # –ó–ê–ì–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –ò–ó –†–ê–ó–ù–´–• –ò–°–¢–û–ß–ù–ò–ö–û–í
        # --------------------------------------------------
        if isinstance(image_input, (str, Path)):

                image_path = Path(image_input)
                logger.info(f"üìÇ Loading image: {image_path}")
                if not image_path.exists():
                    raise FileNotFoundError(f"Image file not found: {image_path}")
                image = Image.open(image_path)

        else:
            raise ValueError("‚ùå Unsupported image input type")

        # --------------------------------------------------
        # –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø
        # --------------------------------------------------
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB, –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        if image.mode != 'RGB':
            logger.debug("Converting image to RGB format")
            image = image.convert('RGB')

        # --------------------------------------------------
        # –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –í –í–ï–ö–¢–û–† –° –ü–û–ú–û–©–¨–Æ CLIP
        # --------------------------------------------------
        logger.info("üñºÔ∏è Processing image with CLIP model...")
        return model.encode(image)

    except Exception as e:
        logger.error(f"üî• Error processing image: {str(e)}")
        raise ValueError(f"Image processing failed: {str(e)}") from e


# =============================================
# –§–£–ù–ö–¶–ò–Ø –°–†–ê–í–ù–ï–ù–ò–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô
# =============================================
def batch_compare(source_image, image_list: list) -> list[tuple[str, float]]:
    """

        source_image: (–∑–∞–≥—Ä—É–∂–∞–µ–º–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º)
        image_list: (–ª–∏—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è)

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ [(–ø—É—Ç—å_–∫_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –æ—Ü–µ–Ω–∫–∞_—Å—Ö–æ–∂–µ—Å—Ç–∏), ...],
        –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–∂–µ—Å—Ç–∏ (–æ—Ç 1.0 –¥–æ 0.0)
    """
    if not image_list:
        logger.warning("‚ö†Ô∏è –õ–∏—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—É—Å—Ç")
        return []

    results = []

    try:
        # =============================================
        # –ü–û–î–ì–û–¢–û–í–ö–ê –ò–°–•–û–î–ù–û–ì–û –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø
        # =============================================
        logger.info(f"üîç –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è...")
        source_embedding = get_image_embedding(source_image)
        source_embedding = source_embedding / np.linalg.norm(source_embedding)

        # =============================================
        # –ü–ê–ö–ï–¢–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –°–ü–ò–°–ö–ê
        # =============================================
        logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è {len(image_list)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

        for img_path in image_list:
            try:
                # 2.1. –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                current_embedding = get_image_embedding(img_path)
                current_embedding = current_embedding / np.linalg.norm(current_embedding)

                # 2.2. –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
                similarity = float(np.dot(source_embedding, current_embedding))
                similarity = max(0.0, min(similarity, 1.0))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º [0, 1]

                # 2.3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                results.append((str(img_path), similarity))

                logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {img_path} ‚Üí {similarity:.2f}")

            except Exception as e:
                logger.warning(f"‚è© –ü—Ä–æ–ø—É—â–µ–Ω–Ω–æ {img_path}: {str(e)}")
                continue

        # =============================================
        # –°–û–†–¢–ò–†–û–í–ö–ê –ò –í–û–ó–í–†–ê–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
        # =============================================
        logger.info("üìä –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç–µ–ø–µ–Ω–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏...")
        sorted_results = sorted(results, key=lambda x: x[1], reverse=True)

        return sorted_results

    except Exception as e:
        logger.error(f"üî• –ù–µ —É–¥–∞–ª–æ—Å—å - –æ—à–∏–±–∫–∞: {str(e)}")
        return []